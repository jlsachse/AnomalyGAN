{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lib.transformers as tf\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwruData0 = pd.read_parquet('data/cwru0.parquet')\n",
    "cwruData1 = pd.read_parquet('data/cwru1.parquet')\n",
    "\n",
    "cwruData = pd.concat([cwruData0, cwruData1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import PassthroughScoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 100  # size of the latent z vector\n",
    "ngf = 32  # units of generator\n",
    "ndf = 32  # units of discriminator\n",
    "nc = 1  # number of channels\n",
    "batch_size = 32\n",
    "lr = 0.0002\n",
    "beta1 = 0.5  # for adam\n",
    "max_epochs = 50\n",
    "ngpu = 1\n",
    "isize = 32  # 32 is easier than 28 to work with\n",
    "workers = 2  # for dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.model import Ganomaly, GanomalyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import TensorBoard\n",
    "\n",
    "class GANomalyBoard(TensorBoard):\n",
    "    def on_epoch_end(self, net, dataset_train, **kwargs):\n",
    "        \n",
    "        epoch = net.history[-1, 'epoch']\n",
    "        \n",
    "        X, fake = extract_images(net, dataset_train)\n",
    "        mean_score = extract_mean_score(net, dataset_train)\n",
    "        \n",
    "        self.writer.add_image('X', X, global_step=epoch)\n",
    "        self.writer.add_image('fake', fake, global_step=epoch)\n",
    "        \n",
    "        self.writer.add_histogram('mean_anomaly_score', mean_score, global_step=epoch)\n",
    "        \n",
    "        super().on_epoch_end(net, **kwargs)  # call super last\n",
    "        \n",
    "def extract_images(net, dataset_train):\n",
    "    generator = net.module_.generator\n",
    "    \n",
    "    X = dataset_train.X[:36]\n",
    "    X = torch.tensor(X)\n",
    "         \n",
    "    fake, latent_i, latent_o = generator(X)\n",
    "    \n",
    "    X = torchvision.utils.make_grid(X, nrow=6)\n",
    "    fake = torchvision.utils.make_grid(fake, nrow=6)\n",
    "    \n",
    "    return X, fake\n",
    "\n",
    "def extract_mean_score(net, dataset_train):\n",
    "  \n",
    "    X = dataset_train.X\n",
    "    X = torch.tensor(X)\n",
    "    \n",
    "    scores = net.module_.forward(X).detach().numpy()\n",
    "    mean_score = np.mean(scores)\n",
    "\n",
    "    return mean_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.writer.add_histogram('bias', bias, global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GanomalyNet(\n",
    "    Ganomaly,\n",
    "    module__isize = isize,\n",
    "    module__nz=nz,\n",
    "    module__ndf=ndf,\n",
    "    module__ngf=ngf,\n",
    "    module__nc=nc,\n",
    "    module__ngpu=ngpu,\n",
    "    \n",
    "    module__w_lat = 1,\n",
    "    \n",
    "    criterion=nn.BCELoss,\n",
    "\n",
    "    optimizer_gen=optim.Adam,\n",
    "    optimizer_gen__lr=0.0002,\n",
    "    optimizer_gen__betas=(beta1, 0.999),\n",
    "\n",
    "    optimizer_dis=optim.Adam,\n",
    "    optimizer_dis__lr=0.00002,\n",
    "    optimizer_dis__betas=(beta1, 0.999),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=max_epochs,\n",
    "\n",
    "    train_split=False,  # not implemented\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=workers,\n",
    "    iterator_valid__num_workers=workers,\n",
    "\n",
    "    callbacks=[\n",
    "        PassthroughScoring('loss_dis', on_train=True),\n",
    "        PassthroughScoring('loss_gen', on_train=True),\n",
    "        PassthroughScoring('loss_gen_fra', on_train=True),\n",
    "        PassthroughScoring('loss_gen_app', on_train=True),\n",
    "        PassthroughScoring('loss_gen_lat', on_train=True),\n",
    "        GANomalyBoard(SummaryWriter())\n",
    "        \n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = tf.DataSelector(columns = ['fanEndData', 'driveEndData'], condition = ['Normal Baseline']).transform(cwruData)\n",
    "inner = tf.DataSelector(columns = ['fanEndData', 'driveEndData'], condition = ['Inner Race Fault']).transform(cwruData)\n",
    "ball = tf.DataSelector(columns = ['fanEndData', 'driveEndData'], condition = ['Ball Fault']).transform(cwruData)\n",
    "outer = tf.DataSelector(columns = ['fanEndData', 'driveEndData'], condition = ['Outer Race Fault']).transform(cwruData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlsachse\\Documents\\Bachelorarbeit\\Implementation\\ganomaly\\lib\\transformers.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_ = np.array(X_)\n",
      "C:\\Users\\jlsachse\\Documents\\Bachelorarbeit\\Implementation\\ganomaly\\lib\\transformers.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_ = np.array(X_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    loss_dis    loss_gen    loss_gen_app    loss_gen_fra    loss_gen_lat    train_loss     dur\n",
      "-------  ----------  ----------  --------------  --------------  --------------  ------------  ------\n",
      "      1      0.6507      1.2140          0.1152          0.6985          0.4003        1.8648  7.9411\n",
      "      2      0.6408      0.8516          0.1033          0.6075          0.1407        1.4924  7.3746\n",
      "      3      0.6299      0.7062          0.0911          0.5281          0.0870        1.3361  7.8487\n",
      "      4      0.6177      0.6032          0.0832          0.4585          0.0614        1.2209  9.0340\n",
      "      5      0.6038      0.5281          0.0778          0.3971          0.0532        1.1319  8.4280\n",
      "      6      0.5887      0.4592          0.0741          0.3430          0.0421        1.0479  7.7969\n",
      "      7      0.5719      0.4047          0.0711          0.2954          0.0381        0.9765  7.8266\n",
      "      8      0.5523      0.3585          0.0693          0.2535          0.0356        0.9108  7.8814\n",
      "      9      0.5305      0.3119          0.0672          0.2170          0.0277        0.8424  7.2883\n",
      "     10      0.5083      0.2808          0.0660          0.1857          0.0292        0.7891  7.3359\n",
      "     11      0.4858      0.2481          0.0648          0.1586          0.0246        0.7338  7.1596\n",
      "     12      0.4638      0.2230          0.0638          0.1358          0.0233        0.6868  7.9707\n",
      "     13      0.4407      0.2003          0.0630          0.1168          0.0205        0.6410  8.3650\n",
      "     14      0.4181      0.1829          0.0623          0.1005          0.0201        0.6011  8.3299\n",
      "     15      0.3965      0.1656          0.0616          0.0874          0.0166        0.5621  7.2741\n",
      "     16      0.3769      0.1539          0.0610          0.0762          0.0166        0.5307  7.9236\n",
      "     17      0.3575      0.1445          0.0606          0.0669          0.0170        0.5019  8.3799\n",
      "     18      0.3400      0.1345          0.0602          0.0589          0.0153        0.4745  7.5260\n",
      "     19      0.3230      0.1265          0.0598          0.0523          0.0145        0.4495  7.1166\n",
      "     20      0.3084      0.1212          0.0595          0.0467          0.0150        0.4296  8.1672\n",
      "     21      0.2935      0.1137          0.0591          0.0419          0.0128        0.4072  7.9452\n",
      "     22      0.2800      0.1092          0.0588          0.0377          0.0127        0.3892  9.0092\n",
      "     23      0.2679      0.1046          0.0585          0.0341          0.0120        0.3726  8.8992\n",
      "     24      0.2559      0.1028          0.0584          0.0311          0.0133        0.3587  9.4854\n",
      "     25      0.2446      0.0966          0.0580          0.0284          0.0101        0.3412  8.4139\n",
      "     26      0.2335      0.0940          0.0577          0.0260          0.0102        0.3275  8.1424\n",
      "     27      0.2256      0.0924          0.0575          0.0240          0.0108        0.3180  9.7929\n",
      "     28      0.2166      0.0907          0.0574          0.0222          0.0111        0.3073  9.9130\n",
      "     29      0.2082      0.0894          0.0573          0.0206          0.0115        0.2976  8.4144\n",
      "     30      0.1998      0.0863          0.0570          0.0192          0.0100        0.2861  8.5383\n",
      "     31      0.1924      0.0853          0.0569          0.0179          0.0105        0.2777  10.8459\n",
      "     32      0.1855      0.0834          0.0567          0.0168          0.0100        0.2689  8.3593\n",
      "     33      0.1791      0.0819          0.0565          0.0157          0.0096        0.2609  8.4991\n",
      "     34      0.1729      0.0798          0.0564          0.0148          0.0086        0.2527  8.7377\n",
      "     35      0.1667      0.0795          0.0562          0.0140          0.0093        0.2462  9.9486\n",
      "     36      0.1609      0.0781          0.0561          0.0132          0.0088        0.2390  8.4688\n",
      "     37      0.1558      0.0771          0.0560          0.0125          0.0086        0.2329  8.0719\n",
      "     38      0.1507      0.0751          0.0558          0.0119          0.0074        0.2258  8.5243\n",
      "     39      0.1458      0.0749          0.0556          0.0113          0.0080        0.2207  10.2184\n",
      "     40      0.1415      0.0744          0.0555          0.0108          0.0081        0.2160  8.1142\n",
      "     41      0.1374      0.0729          0.0553          0.0103          0.0073        0.2103  8.1925\n",
      "     42      0.1333      0.0729          0.0552          0.0098          0.0078        0.2061  10.0629\n",
      "     43      0.1295      0.0710          0.0550          0.0094          0.0066        0.2005  8.9182\n",
      "     44      0.1255      0.0714          0.0549          0.0090          0.0074        0.1969  7.5570\n",
      "     45      0.1224      0.0706          0.0548          0.0086          0.0071        0.1930  7.9709\n",
      "     46      0.1195      0.0700          0.0547          0.0083          0.0070        0.1895  8.7266\n",
      "     47      0.1164      0.0699          0.0546          0.0080          0.0073        0.1862  7.6972\n",
      "     48      0.1135      0.0682          0.0544          0.0077          0.0061        0.1817  7.3752\n",
      "     49      0.1108      0.0677          0.0543          0.0074          0.0061        0.1786  7.0917\n",
      "     50      0.1079      0.0680          0.0541          0.0071          0.0067        0.1759  8.0477\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'module__w_fra': [10, 12],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "prep = \\\n",
    "Pipeline(steps=[\n",
    "                ('ArrayFlattener', tf.ArrayFlattener()),\n",
    "                ('DatatypeFilter', tf.DataTypeFilter(data_type = np.ndarray)),\n",
    "                ('ArrayChunker', tf.ArrayChunker(1024)),\n",
    "                #('ArrayEqualizer', tf.ArrayEqualizer()),\n",
    "                ('ArrayFlattener2', tf.ArrayFlattener()),\n",
    "                ('RandomArraySampler', tf.RandomArraySampler(400, random_state = 0)),\n",
    "                #('FeatureExtractor', tf.FeatureExtractor(axis=1)),\n",
    "                ('ArrayReshaper', tf.ArrayReshaper((1, 32, 32))),\n",
    "                ('GANomaly', net)\n",
    "               ])\n",
    "\n",
    "test = prep.fit(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal mean: 0.030068059\n",
      "inner mean: 0.85998094\n",
      "ball mean: 0.21447766\n",
      "outer mean: 1.155004\n"
     ]
    }
   ],
   "source": [
    "print(\"normal mean:\", prep.predict(normal).mean())\n",
    "print(\"inner mean:\", prep.predict(inner).mean())\n",
    "print(\"ball mean:\", prep.predict(ball).mean())\n",
    "print(\"outer mean:\", prep.predict(outer).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
