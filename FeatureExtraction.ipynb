{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lib.transformers as tf\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwruData0 = pd.read_parquet('data/cwru0.parquet')\n",
    "cwruData1 = pd.read_parquet('data/cwru1.parquet')\n",
    "\n",
    "cwruData = pd.concat([cwruData0, cwruData1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import PassthroughScoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 100  # size of the latent z vector\n",
    "ngf = 32  # units of generator\n",
    "ndf = 32  # units of discriminator\n",
    "nc = 1  # number of channels\n",
    "batch_size = 32\n",
    "lr = 0.0002\n",
    "beta1 = 0.5  # for adam\n",
    "max_epochs = 50\n",
    "ngpu = 1\n",
    "isize = 32  # 32 is easier than 28 to work with\n",
    "workers = 2  # for dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.model import Ganomaly, GanomalyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import TensorBoard\n",
    "\n",
    "class GANomalyBoard(TensorBoard):\n",
    "    def on_epoch_end(self, net, dataset_train, **kwargs):\n",
    "        \n",
    "        epoch = net.history[-1, 'epoch']\n",
    "        \n",
    "        X, fake = extract_images(net, dataset_train)\n",
    "        mean_score = extract_mean_score(net, dataset_train)\n",
    "        \n",
    "        self.writer.add_image('X', X, global_step=epoch)\n",
    "        self.writer.add_image('fake', fake, global_step=epoch)\n",
    "        \n",
    "        self.writer.add_histogram('mean_anomaly_score', mean_score, global_step=epoch)\n",
    "        \n",
    "        super().on_epoch_end(net, **kwargs)  # call super last\n",
    "        \n",
    "def extract_images(net, dataset_train):\n",
    "    generator = net.module_.generator\n",
    "    \n",
    "    X = dataset_train.X[:36]\n",
    "    X = torch.tensor(X)\n",
    "         \n",
    "    fake, latent_i, latent_o = generator(X)\n",
    "    \n",
    "    X = torchvision.utils.make_grid(X, nrow=6)\n",
    "    fake = torchvision.utils.make_grid(fake, nrow=6)\n",
    "    \n",
    "    return X, fake\n",
    "\n",
    "def extract_mean_score(net, dataset_train):\n",
    "  \n",
    "    X = dataset_train.X\n",
    "    X = torch.tensor(X)\n",
    "    \n",
    "    scores = net.module_.forward(X)\n",
    "    mean_score = np.mean(scores)\n",
    "\n",
    "    return mean_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.writer.add_histogram('bias', bias, global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GanomalyNet(\n",
    "    Ganomaly,\n",
    "    module__isize = isize,\n",
    "    module__nz=nz,\n",
    "    module__ndf=ndf,\n",
    "    module__ngf=ngf,\n",
    "    module__nc=nc,\n",
    "    module__ngpu=ngpu,\n",
    "    \n",
    "    module__w_lat = 1,\n",
    "    \n",
    "    criterion=nn.BCELoss,\n",
    "\n",
    "    optimizer_gen=optim.Adam,\n",
    "    optimizer_gen__lr=0.0002,\n",
    "    optimizer_gen__betas=(beta1, 0.999),\n",
    "\n",
    "    optimizer_dis=optim.Adam,\n",
    "    optimizer_dis__lr=0.00002,\n",
    "    optimizer_dis__betas=(beta1, 0.999),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=max_epochs,\n",
    "\n",
    "    train_split=False,  # not implemented\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=workers,\n",
    "    iterator_valid__num_workers=workers,\n",
    "\n",
    "    callbacks=[\n",
    "        PassthroughScoring('loss_dis', on_train=True),\n",
    "        PassthroughScoring('loss_gen', on_train=True),\n",
    "        PassthroughScoring('loss_gen_fra', on_train=True),\n",
    "        PassthroughScoring('loss_gen_app', on_train=True),\n",
    "        PassthroughScoring('loss_gen_lat', on_train=True),\n",
    "        GANomalyBoard(SummaryWriter())\n",
    "        \n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = tf.DataSelector(columns = ['fanEndData', 'driveEndData'], condition = ['Normal Baseline']).transform(cwruData)\n",
    "inner = tf.DataSelector(columns = ['fanEndData', 'driveEndData'], condition = ['Inner Race Fault']).transform(cwruData)\n",
    "ball = tf.DataSelector(columns = ['fanEndData', 'driveEndData'], condition = ['Ball Fault']).transform(cwruData)\n",
    "outer = tf.DataSelector(columns = ['fanEndData', 'driveEndData'], condition = ['Outer Race Fault']).transform(cwruData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlsachse\\Documents\\Bachelorarbeit\\Implementation\\ganomaly\\lib\\transformers.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_ = np.array(X_)\n",
      "C:\\Users\\jlsachse\\Documents\\Bachelorarbeit\\Implementation\\ganomaly\\lib\\transformers.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_ = np.array(X_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    loss_dis    loss_gen    loss_gen_app    loss_gen_fra    loss_gen_lat    train_loss     dur\n",
      "-------  ----------  ----------  --------------  --------------  --------------  ------------  ------\n",
      "      1      0.7979      1.2161          0.1152          0.7007          0.4003        2.0140  8.0338\n",
      "      2      0.7633      0.8584          0.1033          0.6144          0.1407        1.6218  8.1803\n",
      "      3      0.7274      0.7168          0.0911          0.5387          0.0870        1.4442  8.6114\n",
      "      4      0.6898      0.6164          0.0832          0.4718          0.0614        1.3062  8.0242\n",
      "      5      0.6527      0.5433          0.0778          0.4122          0.0532        1.1959  7.6669\n",
      "      6      0.6138      0.4753          0.0741          0.3591          0.0421        1.0892  7.6895\n",
      "      7      0.5757      0.4212          0.0711          0.3120          0.0381        0.9969  7.3087\n",
      "      8      0.5338      0.3748          0.0693          0.2698          0.0356        0.9085  8.2740\n",
      "      9      0.4913      0.3276          0.0672          0.2327          0.0277        0.8189  8.4142\n",
      "     10      0.4510      0.2956          0.0660          0.2005          0.0292        0.7466  7.4947\n",
      "     11      0.4136      0.2619          0.0648          0.1725          0.0246        0.6755  8.1263\n",
      "     12      0.3797      0.2358          0.0638          0.1487          0.0233        0.6156  8.6979\n",
      "     13      0.3466      0.2122          0.0630          0.1287          0.0205        0.5588  7.9157\n",
      "     14      0.3160      0.1939          0.0623          0.1115          0.0201        0.5099  8.2744\n",
      "     15      0.2886      0.1757          0.0616          0.0975          0.0166        0.4643  7.7001\n",
      "     16      0.2655      0.1632          0.0610          0.0856          0.0166        0.4287  8.4535\n",
      "     17      0.2442      0.1531          0.0606          0.0755          0.0170        0.3974  7.5880\n",
      "     18      0.2259      0.1425          0.0602          0.0670          0.0153        0.3683  7.9134\n",
      "     19      0.2087      0.1340          0.0598          0.0597          0.0145        0.3427  7.7529\n",
      "     20      0.1947      0.1281          0.0595          0.0536          0.0150        0.3228  9.3699\n",
      "     21      0.1810      0.1202          0.0591          0.0483          0.0128        0.3012  6.9845\n",
      "     22      0.1691      0.1152          0.0588          0.0437          0.0127        0.2843  7.2922\n",
      "     23      0.1586      0.1102          0.0585          0.0397          0.0120        0.2688  7.8288\n",
      "     24      0.1486      0.1080          0.0584          0.0363          0.0133        0.2565  9.0845\n",
      "     25      0.1394      0.1014          0.0580          0.0332          0.0101        0.2408  8.7183\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'module__w_fra': [10, 12],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "prep = \\\n",
    "Pipeline(steps=[\n",
    "                ('ArrayFlattener', tf.ArrayFlattener()),\n",
    "                ('DatatypeFilter', tf.DataTypeFilter(data_type = np.ndarray)),\n",
    "                ('ArrayChunker', tf.ArrayChunker(1024)),\n",
    "                #('ArrayEqualizer', tf.ArrayEqualizer()),\n",
    "                ('ArrayFlattener2', tf.ArrayFlattener()),\n",
    "                ('RandomArraySampler', tf.RandomArraySampler(400, random_state = 0)),\n",
    "                #('FeatureExtractor', tf.FeatureExtractor(axis=1)),\n",
    "                ('ArrayReshaper', tf.ArrayReshaper((1, 32, 32))),\n",
    "                ('GANomaly', net)\n",
    "               ])\n",
    "\n",
    "test = prep.fit(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"normal mean:\", prep.predict(normal).mean())\n",
    "print(\"inner mean:\", prep.predict(inner).mean())\n",
    "print(\"ball mean:\", prep.predict(ball).mean())\n",
    "print(\"outer mean:\", prep.predict(outer).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
