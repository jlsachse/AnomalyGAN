{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWRU Experiments\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lib.transformers as tf\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from lib.model import Ganomaly, GanomalyNet\n",
    "from lib.visualization import GANomalyBoard, rename_tensorboard_key\n",
    "\n",
    "from skorch.callbacks import PassthroughScoring\n",
    "import torch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwruData0 = pd.read_parquet('data/cwru0.parquet')\n",
    "cwruData1 = pd.read_parquet('data/cwru1.parquet')\n",
    "\n",
    "cwruData = pd.concat([cwruData0, cwruData1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x275ff9b9d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = 100  # size of the latent z vector\n",
    "ngf = 64  # units of generator\n",
    "ndf = 64  # units of discriminator\n",
    "nc = 1  # number of channels\n",
    "batch_size = 32\n",
    "lr = 0.0002\n",
    "beta1 = 0.5  # for adam\n",
    "max_epochs = 5\n",
    "ngpu = 0\n",
    "isize = 56  # 32 is easier than 28 to work with\n",
    "workers = 2  # for dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomaly = GanomalyNet(\n",
    "    Ganomaly,\n",
    "    module__isize = isize,\n",
    "    module__nz=nz,\n",
    "    module__ndf=ndf,\n",
    "    module__ngf=ngf,\n",
    "    module__nc=nc,\n",
    "    module__ngpu=ngpu,\n",
    "    #module__is2d=False,\n",
    "    \n",
    "    module__w_lat = 1,\n",
    "    \n",
    "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    criterion=torch.nn.BCELoss,\n",
    "\n",
    "    optimizer_gen=torch.optim.Adam,\n",
    "    optimizer_gen__lr=0.0002,\n",
    "    optimizer_gen__betas=(beta1, 0.999),\n",
    "\n",
    "    optimizer_dis=torch.optim.Adam,\n",
    "    optimizer_dis__lr=0.00002,\n",
    "    optimizer_dis__betas=(beta1, 0.999),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=100,\n",
    "\n",
    "    train_split=False,  # not implemented\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=workers,\n",
    "    iterator_valid__num_workers=workers,\n",
    "\n",
    "    callbacks=[\n",
    "        PassthroughScoring('loss_dis', on_train=True),\n",
    "        PassthroughScoring('loss_gen', on_train=True),\n",
    "        PassthroughScoring('loss_gen_fra', on_train=True),\n",
    "        PassthroughScoring('loss_gen_app', on_train=True),\n",
    "        PassthroughScoring('loss_gen_lat', on_train=True)  \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Building a pipeline of custom transformers to fetch and preprocess CWRU data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlsachse\\Documents\\Bachelorarbeit\\Implementation\\ganomaly\\lib\\transformers.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_ = np.array(X_)\n"
     ]
    }
   ],
   "source": [
    "image_size = 56\n",
    "\n",
    "selection_pipeline = \\\n",
    "Pipeline(steps=[\n",
    "                ('DataSelector', tf.DataSelector(columns = ['fanEndData', 'driveEndData'], column_values = {'condition': ['Normal Baseline'], 'sampleRate': [12000]})),\n",
    "                ('ArrayFlattener', tf.ArrayFlattener()),\n",
    "                #('ArrayEqualizer', tf.ArrayEqualizer()),\n",
    "                ('ArrayChunker', tf.ArrayChunker(image_size**2)),\n",
    "                ('ArrayFlattener2', tf.ArrayFlattener()),\n",
    "                ('ArrayReshaper', tf.ArrayReshaper((1, image_size, image_size)))\n",
    "               ])\n",
    "\n",
    "chunked_normal_data = selection_pipeline.transform(cwruData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test-split of the normal CWRU data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(chunked_normal_data, train_size = 400, test_size= 451, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_normal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_parameters = {\n",
    "    'module_w_fra': list(range(0, 101, 10)),\n",
    "    'module_w_app': list(range(0, 101, 10)),\n",
    "    'module_w_lat': list(range(0, 101, 10)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomaly_gs = GridSearchCV(ganomaly, search_parameters, refit=False, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ganomaly_gs.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization (best parameters)\n",
    "Adding a TensorBoard for the visualization of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<skorch.callbacks.scoring.PassthroughScoring at 0x2759e5bdc48>,\n",
       " <skorch.callbacks.scoring.PassthroughScoring at 0x2759e5bdc88>,\n",
       " <skorch.callbacks.scoring.PassthroughScoring at 0x2759e5bdcc8>,\n",
       " <skorch.callbacks.scoring.PassthroughScoring at 0x2759e5bdd08>,\n",
       " <skorch.callbacks.scoring.PassthroughScoring at 0x2759e5bdd48>,\n",
       " <lib.visualization.GANomalyBoard at 0x2759e4daf88>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ganomaly_board = GANomalyBoard(SummaryWriter(), key_mapper = rename_tensorboard_key, close_after_train = False)\n",
    "ganomaly.callbacks += [ganomaly_board]\n",
    "\n",
    "ganomaly.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomaly.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomaly.predict(test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomaly.predict(selection_pipeline.set_params(DataSelector__column_values = {'condition': ['Outer Race Fault'], 'sampleRate': [12000]}).transform(cwruData)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
