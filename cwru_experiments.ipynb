{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWRU Experiments\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lib.transformers as tf\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from lib.models import Ganomaly1d, Ganomaly2d, GanomalyFE, GanomalyNet\n",
    "from lib.visualization import GANomalyBoard, rename_tensorboard_key\n",
    "\n",
    "from skorch.callbacks import PassthroughScoring, ProgressBar\n",
    "import torch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import tensorflow\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from lib.others import create_dataset\n",
    "\n",
    "from lib.others import build_model\n",
    "from lib.visualization import lineplot_comparison\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwruData0 = pd.read_parquet('data/cwru0.parquet')\n",
    "cwruData1 = pd.read_parquet('data/cwru1.parquet')\n",
    "\n",
    "cwruData = pd.concat([cwruData0, cwruData1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2005513a8f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_features, normal_labels = create_dataset(cwruData, feature_columns = ['fanEndData', 'driveEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Normal Baseline'], sampleRate = [12000])\n",
    "normal_features_train, normal_features_test, normal_labels_train, normal_labels_test = train_test_split(normal_features, normal_labels, train_size = 400, test_size= 451, random_state = 0)\n",
    "\n",
    "ball_features, ball_labels = create_dataset(cwruData, feature_columns = ['fanEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Ball Fault'], sampleRate = [12000])\n",
    "inner_features, inner_labels = create_dataset(cwruData, feature_columns = ['fanEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Inner Race Fault'], sampleRate = [12000])\n",
    "outer_features, outer_labels = create_dataset(cwruData, feature_columns = ['fanEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Outer Race Fault'], sampleRate = [12000])\n",
    "\n",
    "\n",
    "labels_test = pd.concat([ball_labels, inner_labels, outer_labels, normal_labels_test])\n",
    "features_test = pd.concat([ball_features, inner_features, outer_features, normal_features_test])\n",
    "\n",
    "normal_features_test = np.array(normal_features_test.to_list())\n",
    "normal_features_train = np.array(normal_features_train.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Building a pipeline of custom transformers to fetch and preprocess CWRU data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    appearant_loss    discriminator_loss    fraud_loss    generator_loss    latent_loss    train_loss      dur\n",
      "-------  ----------------  --------------------  ------------  ----------------  -------------  ------------  -------\n",
      "      1            \u001b[36m0.0401\u001b[0m                \u001b[32m0.3508\u001b[0m        \u001b[35m0.7457\u001b[0m            \u001b[31m2.1757\u001b[0m         \u001b[94m0.2281\u001b[0m        \u001b[36m2.5265\u001b[0m  10.9921\n",
      "      2            \u001b[36m0.0128\u001b[0m                \u001b[32m0.0872\u001b[0m        0.7608            \u001b[31m1.1912\u001b[0m         \u001b[94m0.0454\u001b[0m        \u001b[36m1.2784\u001b[0m  12.4826\n",
      "      3            \u001b[36m0.0103\u001b[0m                \u001b[32m0.0513\u001b[0m        0.7658            \u001b[31m1.0986\u001b[0m         \u001b[94m0.0240\u001b[0m        \u001b[36m1.1499\u001b[0m  12.1865\n",
      "      4            \u001b[36m0.0093\u001b[0m                \u001b[32m0.0382\u001b[0m        0.7680            \u001b[31m1.0644\u001b[0m         \u001b[94m0.0165\u001b[0m        \u001b[36m1.1026\u001b[0m  10.5130\n",
      "      5            \u001b[36m0.0089\u001b[0m                \u001b[32m0.0310\u001b[0m        0.7695            \u001b[31m1.0487\u001b[0m         \u001b[94m0.0132\u001b[0m        \u001b[36m1.0798\u001b[0m  10.5069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ArrayRealFFT',\n",
       "                 <lib.transformers.ArrayRealFFT object at 0x000002005CEA38E0>),\n",
       "                ('ArrayReshaper',\n",
       "                 <lib.transformers.ArrayReshaper object at 0x000002005CEA39D0>),\n",
       "                ('StandardScaler',\n",
       "                 <lib.transformers.ArrayMinMaxScaler object at 0x000002005CEA3700>),\n",
       "                ('ArrayRetyper',\n",
       "                 <lib.transformers.ArrayRetyper object at 0x000002005CEA3790>),\n",
       "                ('Model',\n",
       "                 <class 'lib.model...\n",
       "          (pyramid-relu-128): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (pyramid-128-256-convt): Conv1d(128, 256, kernel_size=(16,), stride=(4,), bias=False)\n",
       "          (pyramid-256-batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pyramid-relu-256): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (final-256-1-convt): Conv1d(256, 600, kernel_size=(9,), stride=(1,), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "\n",
    "# ganomaly_timeseries = build_model(Ganomaly1d, 3136, max_epochs, 'timeseries11', plot_type = 'lineplot', plot_shape = 3136, plot_latent_shape =600, n_samples = 4)\n",
    "# ganomaly_stacked_ts = build_model(Ganomaly2d, 56, max_epochs, 'stacked_timeseries11', plot_type = 'lineplot', plot_shape = 3136, plot_latent_shape =600, n_samples = 4)\n",
    "ganomaly_fft = build_model(Ganomaly1d, 1568, max_epochs, 'fourier_transform12', plot_type = 'lineplot', plot_shape = 1568, plot_latent_shape =600, n_samples = 4)\n",
    "# ganomaly_stft = build_model(Ganomaly2d, 56, max_epochs, 'short_term_fourier11', plot_type = 'image', plot_shape = 56, plot_latent_shape =600, n_samples = 36)\n",
    "# ganomaly_fe = build_model(GanomalyFE, 4, max_epochs, 'feature_extraction11', needs_feature_engineering = True, plot_type = 'barplot', plot_shape = 16, n_samples = 4, plot_latent_shape = 32)\n",
    "\n",
    "\n",
    "# model_stft = \\\n",
    "# Pipeline(steps=[\n",
    "#                 ('ArraySTFT', tf.ArraySTFT()),\n",
    "#                 ('StandardScaler', MinMaxScaler()),\n",
    "#                 ('ArrayReshaper2', tf.ArrayReshaper((1, 56, 56))),\n",
    "#                 ('ArrayRetyper', tf.ArrayRetyper(np.float32)),\n",
    "#                 ('Model', ganomaly_stft)\n",
    "#                ])\n",
    "\n",
    "\n",
    "# model_timeseries = \\\n",
    "# Pipeline(steps=[\n",
    "#                 ('StandardScaler', MinMaxScaler()),\n",
    "#                 ('ArrayReshaper', tf.ArrayReshaper((1, 3136))),\n",
    "#                 ('ArrayRetyper', tf.ArrayRetyper(np.float32)),\n",
    "#                 ('Model', ganomaly_timeseries)\n",
    "#                ])\n",
    "\n",
    "# model_stacked_ts = \\\n",
    "# Pipeline(steps=[\n",
    "#                 ('StandardScaler', MinMaxScaler()),\n",
    "#                 ('ArrayReshaper', tf.ArrayReshaper((1, 56, 56))),\n",
    "#                 ('ArrayRetyper', tf.ArrayRetyper(np.float32)),\n",
    "#                 ('Model', ganomaly_stacked_ts)\n",
    "#                ])\n",
    "\n",
    "# model_fe = \\\n",
    "# Pipeline(steps=[\n",
    "#                 ('FeatureExtractor', tf.FeatureExtractor()),\n",
    "#                 ('StandardScaler', MinMaxScaler()),\n",
    "#                 ('ArrayReshaper', tf.ArrayReshaper((1, 4, 4))),\n",
    "#                 ('ArrayRetyper', tf.ArrayRetyper(np.float32)),\n",
    "#                 ('Model', ganomaly_fe)\n",
    "#               ])\n",
    "\n",
    "\n",
    "model_fft = \\\n",
    "Pipeline(steps=[\n",
    "                ('ArrayRealFFT', tf.ArrayRealFFT()),\n",
    "                ('ArrayReshaper', tf.ArrayReshaper((1, 1568))),\n",
    "                ('StandardScaler', tf.ArrayMinMaxScaler()),\n",
    "                ('ArrayRetyper', tf.ArrayRetyper(np.float32)),\n",
    "                ('Model', ganomaly_fft)\n",
    "               ])\n",
    "\n",
    "# model_timeseries.fit(normal_features_train)\n",
    "# model_stacked_ts.fit(normal_features_train)\n",
    "# model_fe.fit(normal_features_train)\n",
    "# model_stft.fit(normal_features_train)\n",
    "model_fft.fit(normal_features_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_parameters = {\n",
    "    'Model__module__w_app': list(range(0, 31, 30)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomaly_gs = GridSearchCV(model_fft, search_parameters, refit=False, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    appearant_loss    discriminator_loss    fraud_loss    generator_loss    latent_loss    train_loss     dur\n",
      "-------  ----------------  --------------------  ------------  ----------------  -------------  ------------  ------\n",
      "      1            \u001b[36m0.1534\u001b[0m                \u001b[32m0.4849\u001b[0m        \u001b[35m0.7519\u001b[0m            \u001b[31m0.9813\u001b[0m         \u001b[94m0.2294\u001b[0m        \u001b[36m1.4661\u001b[0m  7.0277\n",
      "      2            0.1614                \u001b[32m0.1830\u001b[0m        0.7561            \u001b[31m0.7899\u001b[0m         \u001b[94m0.0338\u001b[0m        \u001b[36m0.9729\u001b[0m  6.8462\n",
      "      3            0.1628                \u001b[32m0.1049\u001b[0m        0.7579            \u001b[31m0.7791\u001b[0m         \u001b[94m0.0212\u001b[0m        \u001b[36m0.8840\u001b[0m  6.9363\n",
      "      4            0.1637                \u001b[32m0.0754\u001b[0m        0.7585            \u001b[31m0.7746\u001b[0m         \u001b[94m0.0161\u001b[0m        \u001b[36m0.8500\u001b[0m  6.9009\n",
      "      5            0.1644                \u001b[32m0.0598\u001b[0m        0.7589            \u001b[31m0.7725\u001b[0m         \u001b[94m0.0136\u001b[0m        \u001b[36m0.8323\u001b[0m  6.9288\n",
      "  epoch    appearant_loss    discriminator_loss    fraud_loss    generator_loss    latent_loss    train_loss     dur\n",
      "-------  ----------------  --------------------  ------------  ----------------  -------------  ------------  ------\n",
      "      1            \u001b[36m0.1319\u001b[0m                \u001b[32m0.4843\u001b[0m        \u001b[35m0.7427\u001b[0m            \u001b[31m0.9737\u001b[0m         \u001b[94m0.2310\u001b[0m        \u001b[36m1.4579\u001b[0m  6.7948\n",
      "      2            0.1426                \u001b[32m0.1934\u001b[0m        0.7476            \u001b[31m0.7839\u001b[0m         \u001b[94m0.0363\u001b[0m        \u001b[36m0.9774\u001b[0m  7.0686\n",
      "      3            0.1448                \u001b[32m0.1102\u001b[0m        0.7493            \u001b[31m0.7725\u001b[0m         \u001b[94m0.0232\u001b[0m        \u001b[36m0.8827\u001b[0m  6.7859\n",
      "      4            0.1463                \u001b[32m0.0769\u001b[0m        0.7483            \u001b[31m0.7657\u001b[0m         \u001b[94m0.0174\u001b[0m        \u001b[36m0.8426\u001b[0m  7.0726\n",
      "      5            0.1473                \u001b[32m0.0598\u001b[0m        0.7476            \u001b[31m0.7607\u001b[0m         \u001b[94m0.0131\u001b[0m        \u001b[36m0.8205\u001b[0m  6.7794\n",
      "  epoch    appearant_loss    discriminator_loss    fraud_loss    generator_loss    latent_loss    train_loss     dur\n",
      "-------  ----------------  --------------------  ------------  ----------------  -------------  ------------  ------\n",
      "      1            \u001b[36m0.0826\u001b[0m                \u001b[32m0.4933\u001b[0m        \u001b[35m0.7581\u001b[0m            \u001b[31m3.5622\u001b[0m         \u001b[94m0.3268\u001b[0m        \u001b[36m4.0555\u001b[0m  7.1000\n",
      "      2            \u001b[36m0.0267\u001b[0m                \u001b[32m0.1996\u001b[0m        0.7667            \u001b[31m1.6603\u001b[0m         \u001b[94m0.0928\u001b[0m        \u001b[36m1.8599\u001b[0m  6.7675\n",
      "      3            \u001b[36m0.0157\u001b[0m                \u001b[32m0.1047\u001b[0m        0.7692            \u001b[31m1.2970\u001b[0m         \u001b[94m0.0581\u001b[0m        \u001b[36m1.4016\u001b[0m  6.7904\n",
      "      4            \u001b[36m0.0127\u001b[0m                \u001b[32m0.0728\u001b[0m        0.7691            \u001b[31m1.1910\u001b[0m         \u001b[94m0.0407\u001b[0m        \u001b[36m1.2638\u001b[0m  6.8302\n",
      "      5            \u001b[36m0.0110\u001b[0m                \u001b[32m0.0569\u001b[0m        0.7687            \u001b[31m1.1296\u001b[0m         \u001b[94m0.0294\u001b[0m        \u001b[36m1.1864\u001b[0m  7.2801\n",
      "  epoch    appearant_loss    discriminator_loss    fraud_loss    generator_loss    latent_loss    train_loss     dur\n",
      "-------  ----------------  --------------------  ------------  ----------------  -------------  ------------  ------\n",
      "      1            \u001b[36m0.0653\u001b[0m                \u001b[32m0.5171\u001b[0m        \u001b[35m0.7463\u001b[0m            \u001b[31m3.0661\u001b[0m         \u001b[94m0.3602\u001b[0m        \u001b[36m3.5832\u001b[0m  7.0134\n",
      "      2            \u001b[36m0.0221\u001b[0m                \u001b[32m0.2076\u001b[0m        0.7547            \u001b[31m1.5349\u001b[0m         \u001b[94m0.1159\u001b[0m        \u001b[36m1.7426\u001b[0m  6.8023\n",
      "      3            \u001b[36m0.0145\u001b[0m                \u001b[32m0.0996\u001b[0m        0.7591            \u001b[31m1.2566\u001b[0m         \u001b[94m0.0622\u001b[0m        \u001b[36m1.3562\u001b[0m  6.9870\n",
      "      4            \u001b[36m0.0123\u001b[0m                \u001b[32m0.0680\u001b[0m        0.7608            \u001b[31m1.1695\u001b[0m         \u001b[94m0.0407\u001b[0m        \u001b[36m1.2375\u001b[0m  6.9287\n",
      "      5            \u001b[36m0.0108\u001b[0m                \u001b[32m0.0539\u001b[0m        0.7609            \u001b[31m1.1162\u001b[0m         \u001b[94m0.0304\u001b[0m        \u001b[36m1.1701\u001b[0m  6.7544\n"
     ]
    }
   ],
   "source": [
    "gs = ganomaly_gs.fit(normal_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([34.72871351, 34.7830472 ]),\n",
       " 'std_fit_time': array([0.06977677, 0.13865519]),\n",
       " 'mean_score_time': array([0.53931069, 0.53955626]),\n",
       " 'std_score_time': array([2.23875046e-03, 7.15255737e-07]),\n",
       " 'param_Model__module__w_app': masked_array(data=[0, 30],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'Model__module__w_app': 0}, {'Model__module__w_app': 30}],\n",
       " 'split0_test_generator_loss': array([-0.77237105, -1.11925662]),\n",
       " 'split1_test_generator_loss': array([-0.7644034 , -1.10774088]),\n",
       " 'mean_test_generator_loss': array([-0.76838723, -1.11349875]),\n",
       " 'std_test_generator_loss': array([0.00398383, 0.00575787]),\n",
       " 'rank_test_generator_loss': array([1, 2]),\n",
       " 'split0_test_train_loss': array([-0.83086701, -1.17399347]),\n",
       " 'split1_test_train_loss': array([-0.81963332, -1.15616045]),\n",
       " 'mean_test_train_loss': array([-0.82525017, -1.16507696]),\n",
       " 'std_test_train_loss': array([0.00561685, 0.00891651]),\n",
       " 'rank_test_train_loss': array([1, 2])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ganomaly_gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomaly_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = model_timeseries.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'X', 2: 'fake', 3: 'latent_in', 4: 'latent_o'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['X', 'fake', 'latent_in', 'latent_o']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "selection2 = result[result['index'].isin([20, 6, 160, 0, 1, 2, 3])]\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = 0.3,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "selection = result[((result['faultDiameter'] == 0.021) & (result['motorLoad'] == 0) & (result['vibrationOrigin'] == 'fanEndData')) | (result['condition'] == 'Normal Baseline') & (result['vibrationOrigin'] == 'fanEndData')]\n",
    "\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "sns.stripplot(data = selection, y = 'anomaly_score', x = 'condition', hue = 'relativeFaultPosition', palette = ['grey', 'mediumseagreen', 'salmon', 'cornflowerblue'], ax = ax2, alpha = 0.7, jitter = 0.3, linewidth = .1, size = 7)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set(ylim=(0.07, None))\n",
    "ax2.legend(fontsize='large', title_fontsize='30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_comparison(result, 'X', 'fake', 'Feature Extraction', 'Index', 'Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_comparison(result, 'latent_in', 'latent_o', 'Latent Space', 'Index', 'Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = model_stacked_ts.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'X', 2: 'fake', 3: 'latent_in', 4: 'latent_o'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['X', 'fake', 'latent_in', 'latent_o']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "selection2 = result[result['index'].isin([20, 6, 160, 0, 1, 2, 3])]\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = 0.3,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "selection = result[((result['faultDiameter'] == 0.021) & (result['motorLoad'] == 0) & (result['vibrationOrigin'] == 'fanEndData')) | (result['condition'] == 'Normal Baseline') & (result['vibrationOrigin'] == 'fanEndData')]\n",
    "\n",
    "\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "sns.stripplot(data = selection, y = 'anomaly_score', x = 'condition', hue = 'relativeFaultPosition', palette = ['grey', 'mediumseagreen', 'salmon', 'cornflowerblue'], ax = ax2, alpha = 0.7, jitter = 0.3, linewidth = .1, size = 7)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set(ylim=(0.07, None))\n",
    "ax2.legend(fontsize='large', title_fontsize='30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_comparison(result, 'X', 'fake', 'Feature Extraction', 'Index', 'Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_comparison(result, 'latent_in', 'latent_o', 'Latent Space', 'Index', 'Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = model_fft.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'X', 2: 'fake', 3: 'latent_in', 4: 'latent_o'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['X', 'fake', 'latent_in', 'latent_o']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "selection2 = result[result['index'].isin([20, 6, 160, 0, 1, 2, 3])]\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = 0.3,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "selection = result[((result['faultDiameter'] == 0.021) & (result['motorLoad'] == 0) & (result['vibrationOrigin'] == 'fanEndData')) | (result['condition'] == 'Normal Baseline') & (result['vibrationOrigin'] == 'fanEndData')]\n",
    "\n",
    "\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "sns.stripplot(data = selection, y = 'anomaly_score', x = 'condition', hue = 'relativeFaultPosition', palette = ['grey', 'mediumseagreen', 'salmon', 'cornflowerblue'], ax = ax2, alpha = 0.7, jitter = 0.3, linewidth = .1, size = 7)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set(ylim=(0.07, None))\n",
    "ax2.legend(fontsize='large', title_fontsize='30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_comparison(result, 'X', 'fake', 'Feature Extraction', 'Index', 'Amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_comparison(result, 'latent_in', 'latent_o', 'Latent Space', 'Index', 'Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = model_stft.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'X', 2: 'fake', 3: 'latent_in', 4: 'latent_o'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['X', 'fake', 'latent_in', 'latent_o']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "selection2 = result[result['index'].isin([20, 6, 160, 0, 1, 2, 3])]\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = 0.3,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "selection = result[((result['faultDiameter'] == 0.021) & (result['motorLoad'] == 0) & (result['vibrationOrigin'] == 'fanEndData')) | (result['condition'] == 'Normal Baseline') & (result['vibrationOrigin'] == 'fanEndData')]\n",
    "\n",
    "\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "sns.stripplot(data = selection, y = 'anomaly_score', x = 'condition', hue = 'relativeFaultPosition', palette = ['grey', 'mediumseagreen', 'salmon', 'cornflowerblue'], ax = ax2, alpha = 0.7, jitter = 0.3, linewidth = .1, size = 7)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set(ylim=(0.07, None))\n",
    "ax2.legend(fontsize='large', title_fontsize='30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = model_fe.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'X', 2: 'fake', 3: 'latent_in', 4: 'latent_o'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['X', 'fake', 'latent_in', 'latent_o']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "selection2 = result[result['index'].isin([20, 6, 160, 0, 1, 2, 3])]\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = 0.3,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "selection = result[((result['faultDiameter'] == 0.021) & (result['motorLoad'] == 0) & (result['vibrationOrigin'] == 'fanEndData')) | (result['condition'] == 'Normal Baseline') & (result['vibrationOrigin'] == 'fanEndData')]\n",
    "\n",
    "\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "sns.stripplot(data = selection, y = 'anomaly_score', x = 'condition', hue = 'relativeFaultPosition', palette = ['grey', 'mediumseagreen', 'salmon', 'cornflowerblue'], ax = ax2, alpha = 0.7, jitter = 0.3, linewidth = .1, size = 7)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set(ylim=(0.07, None))\n",
    "ax2.legend(fontsize='large', title_fontsize='30')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
