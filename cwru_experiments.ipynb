{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWRU Experiments\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lib.transformers as tf\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from lib.models import Ganomaly1d, Ganomaly2d, GanomalyFE, GanomalyNet\n",
    "from lib.visualization import GANomalyBoard, rename_tensorboard_key\n",
    "\n",
    "from skorch.callbacks import PassthroughScoring\n",
    "import torch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwruData0 = pd.read_parquet('data/cwru0.parquet')\n",
    "cwruData1 = pd.read_parquet('data/cwru1.parquet')\n",
    "\n",
    "cwruData = pd.concat([cwruData0, cwruData1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ce7f609d90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model, isize, max_epochs, needs_feature_engineering = False, ngpu = 0, nz = 100, ndf = 64, ngf = 64, nc = 1, batch_size = 32, lr = 0.0002, beta1 = 0.5, beta2 = 0.999, workers = 2):\n",
    "    \n",
    "    if not needs_feature_engineering:\n",
    "        output_model = GanomalyNet(\n",
    "            model,\n",
    "            module__isize = isize,\n",
    "            module__nz=nz,\n",
    "            module__ndf=ndf,\n",
    "            module__ngf=ngf,\n",
    "            module__nc=nc,\n",
    "            module__ngpu=ngpu,\n",
    "\n",
    "            device = torch.device(\"cuda:0\") if torch.cuda.is_available() else 'cpu',\n",
    "\n",
    "            criterion=torch.nn.BCELoss,\n",
    "\n",
    "            optimizer_gen=torch.optim.Adam,\n",
    "            optimizer_gen__lr=lr,\n",
    "            optimizer_gen__betas=(beta1, beta2),\n",
    "\n",
    "            optimizer_dis=torch.optim.Adam,\n",
    "            optimizer_dis__lr=lr,\n",
    "            optimizer_dis__betas=(beta1, beta2),\n",
    "\n",
    "            batch_size=batch_size,\n",
    "            max_epochs=max_epochs,\n",
    "\n",
    "            train_split=False,  # not implemented\n",
    "            iterator_train__shuffle=True,\n",
    "            iterator_train__num_workers=workers,\n",
    "            iterator_valid__num_workers=workers,\n",
    "\n",
    "            callbacks=[\n",
    "                PassthroughScoring('loss_dis', on_train=True),\n",
    "                PassthroughScoring('loss_gen', on_train=True),\n",
    "                PassthroughScoring('loss_gen_fra', on_train=True),\n",
    "                PassthroughScoring('loss_gen_app', on_train=True),\n",
    "                PassthroughScoring('loss_gen_lat', on_train=True)  \n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "            output_model = GanomalyNet(\n",
    "            model,\n",
    "            module__isize = isize,\n",
    "            module__ngpu=ngpu,\n",
    "\n",
    "            device = torch.device(\"cuda:0\") if torch.cuda.is_available() else 'cpu',\n",
    "\n",
    "            criterion=torch.nn.BCELoss,\n",
    "\n",
    "            optimizer_gen=torch.optim.Adam,\n",
    "            optimizer_gen__lr=lr,\n",
    "            optimizer_gen__betas=(beta1, beta2),\n",
    "\n",
    "            optimizer_dis=torch.optim.Adam,\n",
    "            optimizer_dis__lr=lr,\n",
    "            optimizer_dis__betas=(beta1, beta2),\n",
    "\n",
    "            batch_size=batch_size,\n",
    "            max_epochs=max_epochs,\n",
    "\n",
    "            train_split=False,  # not implemented\n",
    "            iterator_train__shuffle=True,\n",
    "            iterator_train__num_workers=workers,\n",
    "            iterator_valid__num_workers=workers,\n",
    "\n",
    "            callbacks=[\n",
    "                PassthroughScoring('loss_dis', on_train=True),\n",
    "                PassthroughScoring('loss_gen', on_train=True),\n",
    "                PassthroughScoring('loss_gen_fra', on_train=True),\n",
    "                PassthroughScoring('loss_gen_app', on_train=True),\n",
    "                PassthroughScoring('loss_gen_lat', on_train=True)  \n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    return output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomaly1d56 = build_model(Ganomaly1d, 56, 1)\n",
    "ganomaly1d28 = build_model(Ganomaly1d, 28, 1)\n",
    "\n",
    "ganomaly2d56 = build_model(Ganomaly2d, 56, 1)\n",
    "ganomaly2d28 = build_model(Ganomaly2d, 28, 1)\n",
    "\n",
    "ganomaly_fe = build_model(GanomalyFE, 4, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Building a pipeline of custom transformers to fetch and preprocess CWRU data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 56\n",
    "\n",
    "selection_pipeline = \\\n",
    "Pipeline(steps=[\n",
    "                ('DataSelector', tf.DataSelector(columns = ['fanEndData', 'driveEndData'], column_values = {'condition': ['Normal Baseline'], 'sampleRate': [12000]})),\n",
    "                ('ArrayFlattener', tf.ArrayFlattener()),\n",
    "                #('ArrayEqualizer', tf.ArrayEqualizer()),\n",
    "                ('ArrayChunker', tf.ArrayChunker(image_size**2)),\n",
    "                ('ArrayFlattener2', tf.ArrayFlattener()),\n",
    "                ('FeatureExtractor', tf.FeatureExtractor(axis=1)),\n",
    "                ('ArrayReshaper', tf.ArrayReshaper((1, 4, 4)))\n",
    "               ])\n",
    "\n",
    "chunked_normal_data = selection_pipeline.transform(cwruData) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078, 1, 4, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_normal_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test-split of the normal CWRU data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(chunked_normal_data, train_size = 400, test_size= 400, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_normal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_parameters = {\n",
    "    'module_w_fra': list(range(0, 101, 10)),\n",
    "    'module_w_app': list(range(0, 101, 10)),\n",
    "    'module_w_lat': list(range(0, 101, 10)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ganomaly_gs = GridSearchCV(ganomaly, search_parameters, refit=False, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ganomaly_gs.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization (best parameters)\n",
    "Adding a TensorBoard for the visualization of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<skorch.callbacks.scoring.PassthroughScoring at 0x1ce25211648>,\n",
       " <skorch.callbacks.scoring.PassthroughScoring at 0x1ce25211848>,\n",
       " <skorch.callbacks.scoring.PassthroughScoring at 0x1ce25211688>,\n",
       " <skorch.callbacks.scoring.PassthroughScoring at 0x1ce25211b88>,\n",
       " <skorch.callbacks.scoring.PassthroughScoring at 0x1ce25211ac8>,\n",
       " <lib.visualization.GANomalyBoard at 0x1ce251e1248>,\n",
       " <lib.visualization.GANomalyBoard at 0x1ce254a8f48>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ganomaly_board = GANomalyBoard(SummaryWriter(), key_mapper = rename_tensorboard_key, close_after_train = False)\n",
    "ganomaly1d56.callbacks += [ganomaly_board]\n",
    "\n",
    "ganomaly1d56.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: isize, ngpu.\n",
      "  epoch    loss_dis    loss_gen    loss_gen_app    loss_gen_fra    loss_gen_lat    train_loss     dur\n",
      "-------  ----------  ----------  --------------  --------------  --------------  ------------  ------\n",
      "      1      0.4233      1.7597          1.1551          0.6034          0.0012        2.1830  4.3816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'lib.models.GanomalyNet'>[initialized](\n",
       "  module_=GanomalyFE(\n",
       "    (l_fra): BCELoss()\n",
       "    (l_app): L1Loss()\n",
       "    (l_dis): L1Loss()\n",
       "    (discriminator): DiscriminatorNetFE(\n",
       "      (features): Sequential(\n",
       "        (initial-conv-1-4): Conv2d(1, 4, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "        (pyramid-4-batchnorm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pyramid-4-relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (final-conv-4-8): Conv2d(4, 8, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "        (pyramid-8-batchnorm): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (pyramid-8-relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (classifier): Sequential(\n",
       "        (Sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (generator): GeneratorNetFE(\n",
       "      (encoder1): EncoderFE(\n",
       "        (main): Sequential(\n",
       "          (initial-conv-1-4): Conv2d(1, 4, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "          (pyramid-4-batchnorm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pyramid-4-relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (final-conv-4-8): Conv2d(4, 8, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (decoder): DecoderFE(\n",
       "        (main): Sequential(\n",
       "          (initial-8-{1}-convt): ConvTranspose2d(8, 4, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "          (initial-4-relu): ReLU(inplace=True)\n",
       "          (final-4-1-convt): ConvTranspose2d(4, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "          (final-1-tanh): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (encoder2): EncoderFE(\n",
       "        (main): Sequential(\n",
       "          (initial-conv-1-4): Conv2d(1, 4, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "          (pyramid-4-batchnorm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pyramid-4-relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (final-conv-4-8): Conv2d(4, 8, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ganomaly_fe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "56 / 2 / 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomalyFE.predict(test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganomaly.predict(selection_pipeline.set_params(DataSelector__column_values = {'condition': ['Outer Race Fault'], 'sampleRate': [12000]}).transform(cwruData)[:200]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.zeros([32, 1, 3136], dtype=torch.float32)\n",
    "\n",
    "layer1 = torch.nn.Conv1d(1, 32, 16, stride=4, padding = 7, bias = False)\n",
    "layer2 = torch.nn.Conv1d(32, 64, 16, stride=4, padding = 7, bias = False)\n",
    "layer3 = torch.nn.Conv1d(64, 128, 16, stride=4, padding = 7, bias = False)\n",
    "layer4 = torch.nn.Conv1d(128, 100, 16, stride=2, padding = 0, bias = False)\n",
    "\n",
    "layer5 = torch.nn.ConvTranspose1d(100, 128, 16, stride=2, output_padding = 1, bias = False)\n",
    "layer6 = torch.nn.ConvTranspose1d(128, 64, 16, stride=4, padding = 7, output_padding = 2, bias = False)\n",
    "layer7 = torch.nn.ConvTranspose1d(64, 32, 16, stride=4, padding = 7, output_padding = 2, bias = False)\n",
    "layer8 = torch.nn.ConvTranspose1d(32, 1, 16, stride=4, padding = 7, output_padding = 2, bias = False)\n",
    "\n",
    "print(input_data.shape)\n",
    "\n",
    "output1 = layer1(input_data)\n",
    "print(output1.shape)\n",
    "\n",
    "output2 = layer2(output1)\n",
    "print(output2.shape)\n",
    "\n",
    "output3 = layer3(output2)\n",
    "print(output3.shape)\n",
    "\n",
    "output4 = layer4(output3)\n",
    "print(output4.shape)\n",
    "\n",
    "output5 = layer5(output4)\n",
    "print(output5.shape)\n",
    "\n",
    "output6 = layer6(output5)\n",
    "print(output6.shape)\n",
    "\n",
    "output7 = layer7(output6)\n",
    "print(output7.shape)\n",
    "\n",
    "output8 = layer8(output7)\n",
    "print(output8.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.zeros([32, 1, 56, 56], dtype=torch.float32)\n",
    "\n",
    "layer1 = torch.nn.Conv2d(1, 32, 4, stride=2, padding = 1, bias = False)\n",
    "layer2 = torch.nn.Conv2d(32, 64, 4, stride=2, padding = 1, bias = False)\n",
    "layer3 = torch.nn.Conv2d(64, 128, 4, stride=2, padding = 1, bias = False)\n",
    "layer4 = torch.nn.Conv2d(128, 100, 4, stride=1, padding = 0, bias = False)\n",
    "\n",
    "layer5 = torch.nn.ConvTranspose2d(100, 128, 4, stride=1, padding = 0, bias = False)\n",
    "layer6 = torch.nn.ConvTranspose2d(128, 64, 4, stride=2, padding = 1, bias = False)\n",
    "layer7 = torch.nn.ConvTranspose2d(64, 32, 4, stride=2, padding = 1, bias = False)\n",
    "layer8 = torch.nn.ConvTranspose2d(32, 1, 4, stride=2, padding = 1, bias = False)\n",
    "\n",
    "print(input_data.shape)\n",
    "\n",
    "output1 = layer1(input_data)\n",
    "print(output1.shape)\n",
    "\n",
    "output2 = layer2(output1)\n",
    "print(output2.shape)\n",
    "\n",
    "output3 = layer3(output2)\n",
    "print(output3.shape)\n",
    "\n",
    "output4 = layer4(output3)\n",
    "print(output4.shape)\n",
    "\n",
    "output5 = layer5(output4)\n",
    "print(output5.shape)\n",
    "\n",
    "output6 = layer6(output5)\n",
    "print(output6.shape)\n",
    "\n",
    "output7 = layer7(output6)\n",
    "print(output7.shape)\n",
    "\n",
    "output8 = layer8(output7)\n",
    "print(output8.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
