{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWRU Experiments\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lib.transformers as tfs\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from lib.models import Ganomaly1d, Ganomaly2d, GanomalyFE, GanomalyNet\n",
    "from lib.visualization import GANomalyBoard, rename_tensorboard_key\n",
    "\n",
    "from skorch.callbacks import PassthroughScoring, ProgressBar\n",
    "import torch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "from lib.others import create_dataset\n",
    "\n",
    "from lib.others import build_model\n",
    "from lib.visualization import lineplot_comparison\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwruData0 = pd.read_parquet('data/cwru0.parquet')\n",
    "cwruData1 = pd.read_parquet('data/cwru1.parquet')\n",
    "\n",
    "cwruData = pd.concat([cwruData0, cwruData1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# torch.cuda.manual_seed(0)\n",
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_features, normal_labels = create_dataset(cwruData, feature_columns = ['fanEndData', 'driveEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Normal Baseline'], sampleRate = [12000])\n",
    "normal_features_train, normal_features_test, normal_labels_train, normal_labels_test = train_test_split(normal_features, normal_labels, train_size = 400, test_size= 451, random_state = 0)\n",
    "\n",
    "ball_features, ball_labels = create_dataset(cwruData, feature_columns = ['fanEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Ball Fault'], sampleRate = [12000])\n",
    "inner_features, inner_labels = create_dataset(cwruData, feature_columns = ['fanEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Inner Race Fault'], sampleRate = [12000])\n",
    "outer_features, outer_labels = create_dataset(cwruData, feature_columns = ['fanEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Outer Race Fault'], sampleRate = [12000])\n",
    "\n",
    "\n",
    "labels_test = pd.concat([ball_labels, inner_labels, outer_labels, normal_labels_test])\n",
    "features_test = pd.concat([ball_features, inner_features, outer_features, normal_features_test])\n",
    "\n",
    "normal_features_test = np.array(normal_features_test.to_list())\n",
    "normal_features_train = np.array(normal_features_train.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training the different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model settings\n",
    "n_z = 600\n",
    "n_channels = 1\n",
    "n_feature_maps = 64\n",
    "\n",
    "adversarial_weight = 1\n",
    "contextual_weight = 1\n",
    "encoder_weight = 70\n",
    "lambda_weight = 1/70\n",
    "\n",
    "# training settings\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else 'cpu'\n",
    "n_gpus = 0\n",
    "workers = 2\n",
    "batch_size = 16\n",
    "max_epochs = 1\n",
    "lr = 0.0001\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "# extra callbacks\n",
    "callbacks = []\n",
    "\n",
    "# run number\n",
    "run = 0\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_time_series =\\\n",
    "build_model(\n",
    "    model = Ganomaly1d,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 3136, \n",
    "    n_z = n_z,\n",
    "    n_channels = n_channels,\n",
    "    n_fm_discriminator = n_feature_maps,  \n",
    "    n_fm_generator = n_feature_maps,\n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = 0.0001,\n",
    "    beta1 = 0.5,\n",
    "    beta2 = 0.999, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'timeseries' + str(run),\n",
    "    plot_type = 'lineplot', \n",
    "    plot_shape = 3136, \n",
    "    plot_latent_shape =600, \n",
    "    n_samples = 4,\n",
    "    \n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_time_series = \\\n",
    "Pipeline(steps=[\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 3136))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_time_series)\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_time_series.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_stacked_time_series =\\\n",
    "build_model(\n",
    "    model = Ganomaly2d,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 56, \n",
    "    n_z = n_z,\n",
    "    n_channels = n_channels,\n",
    "    n_fm_discriminator = n_feature_maps,  \n",
    "    n_fm_generator = n_feature_maps,\n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = 0.0001,\n",
    "    beta1 = 0.5,\n",
    "    beta2 = 0.999, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'stacked_timeseries' + str(run), \n",
    "    plot_type = 'lineplot', \n",
    "    plot_shape = 3136, \n",
    "    plot_latent_shape =600, \n",
    "    n_samples = 4,\n",
    "    \n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_stacked_time_series = \\\n",
    "Pipeline(steps=[\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 56, 56))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_stacked_time_series)\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_stacked_time_series.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_frequency_spectrum =\\\n",
    "build_model(\n",
    "    model = Ganomaly1d,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 1568, \n",
    "    n_z = n_z,\n",
    "    n_channels = n_channels,\n",
    "    n_fm_discriminator = n_feature_maps,  \n",
    "    n_fm_generator = n_feature_maps,\n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = lr,\n",
    "    beta1 = beta1,\n",
    "    beta2 = beta2, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'frequency_spectrum' + str(run), \n",
    "    plot_type = 'lineplot', \n",
    "    plot_shape = 1568, \n",
    "    plot_latent_shape = 600, \n",
    "    n_samples = 4,\n",
    "    \n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_frequency_spectrum = \\\n",
    "Pipeline(steps=[\n",
    "                ('fourier_transform', tfs.ArrayFFT()),\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 1568))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_frequency_spectrum)\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_frequency_spectrum.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_spectrogram =\\\n",
    "build_model(\n",
    "    model = Ganomaly2d,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 56, \n",
    "    n_z = n_z,\n",
    "    n_channels = n_channels,\n",
    "    n_fm_discriminator = n_feature_maps,  \n",
    "    n_fm_generator = n_feature_maps,\n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = lr,\n",
    "    beta1 = beta1,\n",
    "    beta2 = beta2, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'spectrograms' + str(run),\n",
    "    plot_type = 'image', \n",
    "    plot_shape = 56, \n",
    "    plot_latent_shape =600, \n",
    "    n_samples = 36,\n",
    "\n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_spectrogram = \\\n",
    "Pipeline(steps=[\n",
    "                ('stft_transform', tfs.ArraySTFT()),\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 56, 56))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_spectrogram)\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_spectrogram.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_feature_extraction =\\\n",
    "build_model(\n",
    "    model = GanomalyFE,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 4, \n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = lr,\n",
    "    beta1 = beta1,\n",
    "    beta2 = beta2, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'feature_extraction' + str(run), \n",
    "    plot_type = 'barplot', \n",
    "    plot_shape = 16, \n",
    "    plot_latent_shape = 32, \n",
    "    n_samples = 4,\n",
    "\n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_feature_extraction = \\\n",
    "Pipeline(steps=[\n",
    "                ('feature_extractor', tfs.FeatureExtractor()),\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 4, 4))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_feature_extraction)\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_feature_extraction.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_time_series.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 6)}, style = 'darkgrid')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Time Series')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Input Comparison Time Series', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Time Series', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_stacked_time_series.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Stacked Time Series')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_stacked-time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Input Comparison Stacked Time Series', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_stacked-time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Stacked Time Series', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_stacked-time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_frequency_spectrum.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Frequency Spectrum')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_frequency-spectrum.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Input Comparison Frequency Spectrum', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_frequency-spectrum.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Frequency Spectrum', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_frequency-spectrum.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_spectrogram.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Spectrogram')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_spectrogram.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Input Comparison Spectrogram', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_spectrogram.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Spectrogram', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_spectrogram.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_feature_extraction.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Feature Extraction')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_feature-extraction.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Feature-Extraction', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_feature-extraction.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Feature Extraction', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_feature-extraction.png', dpi=330, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
