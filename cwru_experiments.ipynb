{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWRU Experiments\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lib.transformers as tfs\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from lib.models import Ganomaly1d, Ganomaly2d, GanomalyFE, GanomalyNet\n",
    "from lib.visualization import GANomalyBoard, rename_tensorboard_key\n",
    "\n",
    "from skorch.callbacks import PassthroughScoring, ProgressBar\n",
    "import torch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "from lib.others import create_dataset\n",
    "\n",
    "from lib.others import build_model\n",
    "from lib.visualization import lineplot_comparison\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwruData0 = pd.read_parquet('data/cwru0.parquet')\n",
    "cwruData1 = pd.read_parquet('data/cwru1.parquet')\n",
    "\n",
    "cwruData = pd.concat([cwruData0, cwruData1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# torch.cuda.manual_seed(0)\n",
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_features, normal_labels = create_dataset(cwruData, feature_columns = ['fanEndData', 'driveEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Normal Baseline'], sampleRate = [12000])\n",
    "normal_features_train, normal_features_test, normal_labels_train, normal_labels_test = train_test_split(normal_features, normal_labels, train_size = 400, test_size= 451, random_state = 0)\n",
    "\n",
    "ball_features, ball_labels = create_dataset(cwruData, feature_columns = ['fanEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Ball Fault'], sampleRate = [12000])\n",
    "inner_features, inner_labels = create_dataset(cwruData, feature_columns = ['fanEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Inner Race Fault'], sampleRate = [12000])\n",
    "outer_features, outer_labels = create_dataset(cwruData, feature_columns = ['fanEndData'], label_columns = ['condition', 'faultDiameter', 'motorLoad', 'relativeFaultPosition', 'faultyBearingPosition'], condition = ['Outer Race Fault'], sampleRate = [12000])\n",
    "\n",
    "\n",
    "labels_test = pd.concat([ball_labels, inner_labels, outer_labels, normal_labels_test])\n",
    "features_test = pd.concat([ball_features, inner_features, outer_features, normal_features_test])\n",
    "\n",
    "normal_features_test = np.array(normal_features_test.to_list())\n",
    "normal_features_train = np.array(normal_features_train.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training the different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model settings\n",
    "n_z = 600\n",
    "n_channels = 1\n",
    "n_feature_maps = 64\n",
    "\n",
    "adversarial_weight = 1\n",
    "contextual_weight = 1\n",
    "encoder_weight = 70\n",
    "lambda_weight = 1/70\n",
    "\n",
    "# training settings\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else 'cpu'\n",
    "n_gpus = 0\n",
    "workers = 2\n",
    "batch_size = 16\n",
    "max_epochs = 300\n",
    "lr = 0.0001\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "# extra callbacks\n",
    "callbacks = []\n",
    "\n",
    "# run number\n",
    "run = 0\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_time_series =\\\n",
    "build_model(\n",
    "    model = Ganomaly1d,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 3136, \n",
    "    n_z = n_z,\n",
    "    n_channels = n_channels,\n",
    "    n_fm_discriminator = n_feature_maps,  \n",
    "    n_fm_generator = n_feature_maps,\n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = 0.0001,\n",
    "    beta1 = 0.5,\n",
    "    beta2 = 0.999, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'timeseries' + str(run),\n",
    "    plot_type = 'lineplot', \n",
    "    plot_shape = 3136, \n",
    "    plot_latent_shape =600, \n",
    "    n_samples = 4,\n",
    "    \n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_time_series = \\\n",
    "Pipeline(steps=[\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 3136))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_time_series)\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_time_series.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_stacked_time_series =\\\n",
    "build_model(\n",
    "    model = Ganomaly2d,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 56, \n",
    "    n_z = n_z,\n",
    "    n_channels = n_channels,\n",
    "    n_fm_discriminator = n_feature_maps,  \n",
    "    n_fm_generator = n_feature_maps,\n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = 0.0001,\n",
    "    beta1 = 0.5,\n",
    "    beta2 = 0.999, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'stacked_timeseries' + str(run), \n",
    "    plot_type = 'lineplot', \n",
    "    plot_shape = 3136, \n",
    "    plot_latent_shape =600, \n",
    "    n_samples = 4,\n",
    "    \n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_stacked_time_series = \\\n",
    "Pipeline(steps=[\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 56, 56))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_stacked_time_series)\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_stacked_time_series.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_frequency_spectrum =\\\n",
    "build_model(\n",
    "    model = Ganomaly1d,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 1568, \n",
    "    n_z = n_z,\n",
    "    n_channels = n_channels,\n",
    "    n_fm_discriminator = n_feature_maps,  \n",
    "    n_fm_generator = n_feature_maps,\n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = lr,\n",
    "    beta1 = beta1,\n",
    "    beta2 = beta2, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'frequency_spectrum' + str(run), \n",
    "    plot_type = 'lineplot', \n",
    "    plot_shape = 1568, \n",
    "    plot_latent_shape = 600, \n",
    "    n_samples = 4,\n",
    "    \n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_frequency_spectrum = \\\n",
    "Pipeline(steps=[\n",
    "                ('fourier_transform', tfs.ArrayFFT()),\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 1568))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_frequency_spectrum)\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_frequency_spectrum.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_spectrogram =\\\n",
    "build_model(\n",
    "    model = Ganomaly2d,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 56, \n",
    "    n_z = n_z,\n",
    "    n_channels = n_channels,\n",
    "    n_fm_discriminator = n_feature_maps,  \n",
    "    n_fm_generator = n_feature_maps,\n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = lr,\n",
    "    beta1 = beta1,\n",
    "    beta2 = beta2, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'spectrograms' + str(run),\n",
    "    plot_type = 'image', \n",
    "    plot_shape = 56, \n",
    "    plot_latent_shape =600, \n",
    "    n_samples = 36,\n",
    "\n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_spectrogram = \\\n",
    "Pipeline(steps=[\n",
    "                ('stft_transform', tfs.ArraySTFT()),\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 56, 56))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_spectrogram)\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_spectrogram.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_feature_extraction =\\\n",
    "build_model(\n",
    "    model = GanomalyFE,\n",
    "    \n",
    "    # model parameters\n",
    "    input_size = 4, \n",
    "    adversarial_weight = adversarial_weight,\n",
    "    contextual_weight = contextual_weight, \n",
    "    encoder_weight = encoder_weight,\n",
    "    lambda_weight = lambda_weight,\n",
    "    \n",
    "    # training parameters\n",
    "    device = device,\n",
    "    n_gpus = n_gpus,\n",
    "    workers = workers,\n",
    "    batch_size = batch_size,\n",
    "    max_epochs = max_epochs, \n",
    "    lr = lr,\n",
    "    beta1 = beta1,\n",
    "    beta2 = beta2, \n",
    "    \n",
    "    # logging parameters\n",
    "    suffix = 'feature_extraction' + str(run), \n",
    "    plot_type = 'barplot', \n",
    "    plot_shape = 16, \n",
    "    plot_latent_shape = 32, \n",
    "    n_samples = 4,\n",
    "\n",
    "    # extra callbacks\n",
    "    callbacks = callbacks,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_feature_extraction = \\\n",
    "Pipeline(steps=[\n",
    "                ('feature_extractor', tfs.FeatureExtractor()),\n",
    "                ('reshaper', tfs.ArrayReshaper((1, 4, 4))),\n",
    "                ('retyper', tfs.ArrayRetyper(np.float32)),\n",
    "                ('model', gan_feature_extraction)\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 9860) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-aecabb3a2432>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipeline_feature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_features_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    901\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_train_begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_epoch_begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mon_epoch_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             self.run_single_epoch(dataset_train, training=True, prefix=\"train\",\n\u001b[0m\u001b[0;32m    776\u001b[0m                                   step_fn=self.train_step, **fit_params)\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mrun_single_epoch\u001b[1;34m(self, dataset, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[0mbatch_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m             \u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpack_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[0myi_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myi\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_placeholder_y\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AnomalyGan\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 9860) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "pipeline_feature_extraction.fit(normal_features_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_time_series.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 6)}, style = 'darkgrid')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Time Series')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Input Comparison Time Series', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Time Series', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_stacked_time_series.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Stacked Time Series')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_stacked-time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Input Comparison Stacked Time Series', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_stacked-time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Stacked Time Series', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_stacked-time-series.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_frequency_spectrum.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Frequency Spectrum')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_frequency-spectrum.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Input Comparison Frequency Spectrum', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_frequency-spectrum.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Frequency Spectrum', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_frequency-spectrum.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_spectrogram.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Spectrogram')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_spectrogram.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Input Comparison Spectrogram', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_spectrogram.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Spectrogram', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_spectrogram.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.array(features_test.tolist())\n",
    "predictions = pipeline_feature_extraction.predict_proba(features_test)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions = predictions.T\n",
    "predictions = predictions.rename({0: 'anomaly_score', 1: 'Input', 2: 'Input Reconstruction', 3: 'Latent Input', 4: 'Latent Reconstruction'}, axis = 1)\n",
    "\n",
    "columns_flatten = ['Input', 'Input Reconstruction', 'Latent Input', 'Latent Reconstruction']\n",
    "predictions[columns_flatten] = predictions[columns_flatten].applymap(lambda array: array.flatten())\n",
    "\n",
    "\n",
    "result = labels_test.reset_index(drop=True).join(predictions)\n",
    "result  = result.reset_index(drop = True)\n",
    "\n",
    "\n",
    "result['relativeFaultPosition'] = result['relativeFaultPosition'].fillna('not available')\n",
    "result['faultDiameter'] = result['faultDiameter'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "jitter = 0.3\n",
    "offset = 0.05\n",
    "\n",
    "sns.stripplot(data = result, y = 'anomaly_score', x = 'condition', palette = ['mediumseagreen', 'lightsalmon', 'cornflowerblue', 'lightcoral'], alpha = 0.7, jitter = jitter,  ax = ax, linewidth = .1, size = 7)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for y, condition in enumerate(result['condition'].unique()):\n",
    "    condition_results = result[result['condition'] == condition]['anomaly_score'].astype(np.float32)\n",
    "    ax.text(y + jitter + offset, condition_results.max(), condition_results.max().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.mean(), condition_results.mean().round(3))\n",
    "    ax.text(y + jitter + offset, condition_results.min(), condition_results.min().round(3))\n",
    "    \n",
    "ax.set_xlim(None, y + jitter + offset + 0.3)\n",
    "    \n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_title('Anomaly Score Feature Extraction')\n",
    "\n",
    "fig.savefig('data/results/anomaly-score_feature-extraction.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Input', 'Input Reconstruction', 'Feature-Extraction', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/input-reconstruction_feature-extraction.png', dpi=330, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = lineplot_comparison(result, 'Latent Input', 'Latent Reconstruction', 'Latent Comparison Feature Extraction', 'Index', 'Amplitude')\n",
    "comparison.savefig('data/results/latent-reconstruction_feature-extraction.png', dpi=330, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
