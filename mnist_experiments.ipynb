{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Experiments\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "from lib.others import build_model\n",
    "from lib.models import Ganomaly1d, Ganomaly2d\n",
    "\n",
    "(images, labels), (_, _) = mnist.load_data()\n",
    "indices = [index for index, label in enumerate(labels) if label == 8]\n",
    "\n",
    "X = images[indices][:400]\n",
    "\n",
    "X = X.reshape((-1, 1, 28, 28))\n",
    "\n",
    "X = np.array(X, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = build_model(Ganomaly2d, 28, 50, 'mnist2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    loss_dis    loss_gen    loss_gen_app    loss_gen_fra    loss_gen_lat    train_loss      dur\n",
      "-------  ----------  ----------  --------------  --------------  --------------  ------------  -------\n",
      "      1      \u001b[36m0.3154\u001b[0m   \u001b[32m1125.6259\u001b[0m         \u001b[35m37.4846\u001b[0m          \u001b[31m0.7466\u001b[0m          \u001b[94m0.3408\u001b[0m     \u001b[36m1125.9413\u001b[0m  11.7350\n",
      "      2      \u001b[36m0.1182\u001b[0m   \u001b[32m1123.1165\u001b[0m         \u001b[35m37.4089\u001b[0m          0.7524          \u001b[94m0.0965\u001b[0m     \u001b[36m1123.2348\u001b[0m  13.1663\n",
      "      3      \u001b[36m0.0925\u001b[0m   \u001b[32m1122.5925\u001b[0m         \u001b[35m37.3923\u001b[0m          0.7545          \u001b[94m0.0684\u001b[0m     \u001b[36m1122.6849\u001b[0m  12.2161\n",
      "      4      \u001b[36m0.0789\u001b[0m   \u001b[32m1122.2559\u001b[0m         \u001b[35m37.3815\u001b[0m          0.7550          \u001b[94m0.0545\u001b[0m     \u001b[36m1122.3348\u001b[0m  13.1244\n",
      "      5      \u001b[36m0.0695\u001b[0m   \u001b[32m1121.9978\u001b[0m         \u001b[35m37.3730\u001b[0m          0.7552          \u001b[94m0.0519\u001b[0m     \u001b[36m1122.0673\u001b[0m  10.9130\n",
      "      6      \u001b[36m0.0631\u001b[0m   \u001b[32m1121.7796\u001b[0m         \u001b[35m37.3659\u001b[0m          0.7557          \u001b[94m0.0481\u001b[0m     \u001b[36m1121.8427\u001b[0m  11.4598\n",
      "      7      \u001b[36m0.0565\u001b[0m   \u001b[32m1121.5881\u001b[0m         \u001b[35m37.3596\u001b[0m          0.7562          \u001b[94m0.0436\u001b[0m     \u001b[36m1121.6446\u001b[0m  10.6652\n",
      "      8      \u001b[36m0.0515\u001b[0m   \u001b[32m1121.4514\u001b[0m         \u001b[35m37.3551\u001b[0m          0.7568          \u001b[94m0.0417\u001b[0m     \u001b[36m1121.5029\u001b[0m  11.1925\n",
      "      9      \u001b[36m0.0466\u001b[0m   \u001b[32m1121.3321\u001b[0m         \u001b[35m37.3511\u001b[0m          0.7572          \u001b[94m0.0417\u001b[0m     \u001b[36m1121.3787\u001b[0m  11.8435\n",
      "     10      \u001b[36m0.0422\u001b[0m   \u001b[32m1121.2372\u001b[0m         \u001b[35m37.3480\u001b[0m          0.7576          \u001b[94m0.0410\u001b[0m     \u001b[36m1121.2795\u001b[0m  11.7275\n",
      "     11      \u001b[36m0.0382\u001b[0m   \u001b[32m1121.1266\u001b[0m         \u001b[35m37.3443\u001b[0m          0.7581          \u001b[94m0.0407\u001b[0m     \u001b[36m1121.1647\u001b[0m  11.8870\n",
      "     12      \u001b[36m0.0347\u001b[0m   \u001b[32m1121.0260\u001b[0m         \u001b[35m37.3409\u001b[0m          0.7584          \u001b[94m0.0396\u001b[0m     \u001b[36m1121.0607\u001b[0m  11.7781\n",
      "     13      \u001b[36m0.0321\u001b[0m   \u001b[32m1120.9625\u001b[0m         \u001b[35m37.3388\u001b[0m          0.7587          0.0405     \u001b[36m1120.9946\u001b[0m  11.4848\n",
      "     14      \u001b[36m0.0297\u001b[0m   \u001b[32m1120.8779\u001b[0m         \u001b[35m37.3360\u001b[0m          0.7590          \u001b[94m0.0396\u001b[0m     \u001b[36m1120.9076\u001b[0m  11.1679\n",
      "     15      \u001b[36m0.0272\u001b[0m   \u001b[32m1120.7825\u001b[0m         \u001b[35m37.3328\u001b[0m          0.7594          \u001b[94m0.0387\u001b[0m     \u001b[36m1120.8097\u001b[0m  11.1809\n",
      "     16      \u001b[36m0.0254\u001b[0m   \u001b[32m1120.7174\u001b[0m         \u001b[35m37.3306\u001b[0m          0.7598          \u001b[94m0.0382\u001b[0m     \u001b[36m1120.7428\u001b[0m  11.0692\n",
      "     17      \u001b[36m0.0239\u001b[0m   \u001b[32m1120.6434\u001b[0m         \u001b[35m37.3282\u001b[0m          0.7600          0.0383     \u001b[36m1120.6673\u001b[0m  11.6093\n",
      "     18      \u001b[36m0.0224\u001b[0m   \u001b[32m1120.5571\u001b[0m         \u001b[35m37.3254\u001b[0m          0.7602          \u001b[94m0.0360\u001b[0m     \u001b[36m1120.5795\u001b[0m  11.2113\n",
      "     19      \u001b[36m0.0210\u001b[0m   \u001b[32m1120.5077\u001b[0m         \u001b[35m37.3237\u001b[0m          0.7603          0.0365     \u001b[36m1120.5287\u001b[0m  11.1815\n",
      "     20      \u001b[36m0.0201\u001b[0m   \u001b[32m1120.4554\u001b[0m         \u001b[35m37.3220\u001b[0m          0.7605          0.0363     \u001b[36m1120.4755\u001b[0m  11.1132\n",
      "     21      \u001b[36m0.0192\u001b[0m   \u001b[32m1120.3990\u001b[0m         \u001b[35m37.3201\u001b[0m          0.7608          0.0365     \u001b[36m1120.4182\u001b[0m  10.9791\n",
      "     22      \u001b[36m0.0182\u001b[0m   \u001b[32m1120.3387\u001b[0m         \u001b[35m37.3181\u001b[0m          0.7609          \u001b[94m0.0353\u001b[0m     \u001b[36m1120.3569\u001b[0m  11.0272\n",
      "     23      \u001b[36m0.0173\u001b[0m   \u001b[32m1120.2929\u001b[0m         \u001b[35m37.3166\u001b[0m          0.7610          \u001b[94m0.0347\u001b[0m     \u001b[36m1120.3103\u001b[0m  11.5258\n",
      "     24      \u001b[36m0.0169\u001b[0m   \u001b[32m1120.2526\u001b[0m         \u001b[35m37.3152\u001b[0m          0.7611          0.0354     \u001b[36m1120.2695\u001b[0m  11.1587\n",
      "     25      \u001b[36m0.0162\u001b[0m   \u001b[32m1120.2139\u001b[0m         \u001b[35m37.3139\u001b[0m          0.7612          0.0350     \u001b[36m1120.2301\u001b[0m  11.0877\n",
      "     26      \u001b[36m0.0152\u001b[0m   \u001b[32m1120.1655\u001b[0m         \u001b[35m37.3123\u001b[0m          0.7613          0.0355     \u001b[36m1120.1808\u001b[0m  11.8129\n",
      "     27      \u001b[36m0.0149\u001b[0m   \u001b[32m1120.1408\u001b[0m         \u001b[35m37.3114\u001b[0m          0.7615          0.0362     \u001b[36m1120.1557\u001b[0m  12.1692\n",
      "     28      \u001b[36m0.0143\u001b[0m   \u001b[32m1120.0940\u001b[0m         \u001b[35m37.3099\u001b[0m          0.7616          0.0348     \u001b[36m1120.1084\u001b[0m  14.2605\n",
      "     29      \u001b[36m0.0139\u001b[0m   \u001b[32m1120.0482\u001b[0m         \u001b[35m37.3084\u001b[0m          0.7616          \u001b[94m0.0344\u001b[0m     \u001b[36m1120.0621\u001b[0m  20.3357\n",
      "     30      \u001b[36m0.0133\u001b[0m   \u001b[32m1120.0142\u001b[0m         \u001b[35m37.3073\u001b[0m          0.7618          \u001b[94m0.0335\u001b[0m     \u001b[36m1120.0275\u001b[0m  12.8873\n",
      "     31      \u001b[36m0.0130\u001b[0m   \u001b[32m1119.9686\u001b[0m         \u001b[35m37.3058\u001b[0m          0.7620          \u001b[94m0.0324\u001b[0m     \u001b[36m1119.9816\u001b[0m  12.0652\n",
      "     32      \u001b[36m0.0127\u001b[0m   \u001b[32m1119.9409\u001b[0m         \u001b[35m37.3049\u001b[0m          0.7621          0.0327     \u001b[36m1119.9536\u001b[0m  9.6912\n",
      "     33      \u001b[36m0.0124\u001b[0m   \u001b[32m1119.9311\u001b[0m         \u001b[35m37.3045\u001b[0m          0.7621          0.0334     \u001b[36m1119.9435\u001b[0m  9.5520\n",
      "     34      \u001b[36m0.0121\u001b[0m   \u001b[32m1119.9087\u001b[0m         \u001b[35m37.3037\u001b[0m          0.7622          0.0341     \u001b[36m1119.9208\u001b[0m  14.9237\n",
      "     35      \u001b[36m0.0118\u001b[0m   \u001b[32m1119.8754\u001b[0m         \u001b[35m37.3026\u001b[0m          0.7624          0.0341     \u001b[36m1119.8872\u001b[0m  14.4911\n",
      "     36      \u001b[36m0.0113\u001b[0m   \u001b[32m1119.8343\u001b[0m         \u001b[35m37.3013\u001b[0m          0.7625          0.0331     \u001b[36m1119.8455\u001b[0m  12.1280\n",
      "     37      \u001b[36m0.0110\u001b[0m   \u001b[32m1119.8095\u001b[0m         \u001b[35m37.3005\u001b[0m          0.7627          0.0327     \u001b[36m1119.8205\u001b[0m  11.5779\n",
      "     38      \u001b[36m0.0108\u001b[0m   \u001b[32m1119.7963\u001b[0m         \u001b[35m37.3000\u001b[0m          0.7630          0.0335     \u001b[36m1119.8072\u001b[0m  12.9192\n",
      "     39      \u001b[36m0.0105\u001b[0m   \u001b[32m1119.7633\u001b[0m         \u001b[35m37.2989\u001b[0m          0.7633          0.0328     \u001b[36m1119.7737\u001b[0m  11.4312\n",
      "     40      \u001b[36m0.0103\u001b[0m   \u001b[32m1119.7374\u001b[0m         \u001b[35m37.2981\u001b[0m          0.7635          0.0324     \u001b[36m1119.7477\u001b[0m  11.6094\n",
      "     41      \u001b[36m0.0102\u001b[0m   \u001b[32m1119.7156\u001b[0m         \u001b[35m37.2973\u001b[0m          0.7635          \u001b[94m0.0323\u001b[0m     \u001b[36m1119.7258\u001b[0m  11.2210\n",
      "     42      \u001b[36m0.0099\u001b[0m   \u001b[32m1119.6936\u001b[0m         \u001b[35m37.2966\u001b[0m          0.7638          0.0323     \u001b[36m1119.7035\u001b[0m  12.0201\n",
      "     43      \u001b[36m0.0097\u001b[0m   \u001b[32m1119.6929\u001b[0m         \u001b[35m37.2965\u001b[0m          0.7639          0.0333     \u001b[36m1119.7026\u001b[0m  11.2412\n",
      "     44      \u001b[36m0.0094\u001b[0m   \u001b[32m1119.6622\u001b[0m         \u001b[35m37.2955\u001b[0m          0.7642          0.0328     \u001b[36m1119.6716\u001b[0m  11.3209\n",
      "     45      0.0095   \u001b[32m1119.6378\u001b[0m         \u001b[35m37.2947\u001b[0m          0.7643          \u001b[94m0.0322\u001b[0m     \u001b[36m1119.6472\u001b[0m  12.1099\n",
      "     46      \u001b[36m0.0092\u001b[0m   \u001b[32m1119.6185\u001b[0m         \u001b[35m37.2941\u001b[0m          0.7643          \u001b[94m0.0318\u001b[0m     \u001b[36m1119.6277\u001b[0m  11.4793\n",
      "     47      \u001b[36m0.0088\u001b[0m   \u001b[32m1119.5965\u001b[0m         \u001b[35m37.2934\u001b[0m          0.7645          \u001b[94m0.0312\u001b[0m     \u001b[36m1119.6052\u001b[0m  14.0654\n",
      "     48      \u001b[36m0.0088\u001b[0m   \u001b[32m1119.5766\u001b[0m         \u001b[35m37.2927\u001b[0m          0.7645          0.0315     \u001b[36m1119.5853\u001b[0m  12.4858\n",
      "     49      \u001b[36m0.0085\u001b[0m   \u001b[32m1119.5615\u001b[0m         \u001b[35m37.2922\u001b[0m          0.7645          0.0316     \u001b[36m1119.5700\u001b[0m  12.1808\n",
      "     50      0.0085   \u001b[32m1119.5394\u001b[0m         \u001b[35m37.2915\u001b[0m          0.7646          \u001b[94m0.0310\u001b[0m     \u001b[36m1119.5479\u001b[0m  11.4401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'lib.models.GanomalyNet'>[initialized](\n",
       "  module_=Ganomaly2d(\n",
       "    (l_fra): BCELoss()\n",
       "    (l_app): L1Loss()\n",
       "    (l_dis): L1Loss()\n",
       "    (discriminator): DiscriminatorNet2d(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "      (classifier): Sequential(\n",
       "        (0): Conv2d(256, 600, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (Sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (generator): GeneratorNet2d(\n",
       "      (encoder1): Encoder2d(\n",
       "        (main): Sequential(\n",
       "          (initial-conv-1-64): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (initial-relu-64): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (pyramid-64-128-conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (pyramid-128-batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pyramid-128-relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (pyramid-128-256-conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (pyramid-256-batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pyramid-256-relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (final-256-1-conv): Conv2d(256, 600, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (decoder): Decoder2d(\n",
       "        (main): Sequential(\n",
       "          (initial-600-256-convt): ConvTranspose2d(600, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (initial-256-batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (initial-256-relu): ReLU(inplace=True)\n",
       "          (initial-256-128-convt): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "          (initial-128-batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (initial-128-relu): ReLU(inplace=True)\n",
       "          (pyramid-128-64-convt): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (pyramid-64-batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pyramid-64-relu): ReLU(inplace=True)\n",
       "          (final-64-1-convt): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (final-1-tanh): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (encoder2): Encoder2d(\n",
       "        (main): Sequential(\n",
       "          (initial-conv-1-64): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (initial-relu-64): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (pyramid-64-128-conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (pyramid-128-batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pyramid-128-relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (pyramid-128-256-conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (pyramid-256-batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (pyramid-256-relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (final-256-1-conv): Conv2d(256, 600, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.fit(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
